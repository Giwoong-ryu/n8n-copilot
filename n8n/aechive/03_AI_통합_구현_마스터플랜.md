# 🎯 Claude + GPT + Gemini 3-Way 통합 웹앱 마스터플랜

**작성일**: 2025-10-30  
**프로젝트**: 멀티 AI 메시징 API 통합 플랫폼  
**목표**: 3개 AI를 하나의 인터페이스에서 사용 가능한 웹앱 구축

---

## 📋 목차

1. [통합 아키텍처 개요](#통합-아키텍처-개요)
2. [AI별 특징 비교](#ai별-특징-비교)
3. [Phase별 구현 계획](#phase별-구현-계획)
4. [기술 스택 결정](#기술-스택-결정)
5. [API 통합 전략](#api-통합-전략)
6. [UI/UX 설계](#uiux-설계)
7. [비용 최적화 전략](#비용-최적화-전략)
8. [구현 우선순위](#구현-우선순위)

---

## 🏗️ 통합 아키텍처 개요

### 시스템 구조

```
┌─────────────────────────────────────────────┐
│           Frontend (React/Vanilla JS)        │
│  ┌─────────┬─────────┬─────────┬──────────┐ │
│  │ Chat UI │ Preset  │ Token   │ History  │ │
│  │         │ Manager │ Counter │ Panel    │ │
│  └─────────┴─────────┴─────────┴──────────┘ │
└──────────────────┬──────────────────────────┘
                   │ WebSocket/SSE
┌──────────────────┴──────────────────────────┐
│         Backend API Server (FastAPI)        │
│  ┌──────────────────────────────────────┐   │
│  │      AI Router (통합 라우터)         │   │
│  ├──────────┬──────────┬────────────────┤   │
│  │ Claude   │   GPT    │    Gemini      │   │
│  │ Handler  │ Handler  │    Handler     │   │
│  └──────────┴──────────┴────────────────┘   │
│  ┌──────────────────────────────────────┐   │
│  │    Shared Services                   │   │
│  │  - Token Counter                     │   │
│  │  - Cost Calculator                   │   │
│  │  - Caching Layer                     │   │
│  │  - Error Handler                     │   │
│  │  - Rate Limiter                      │   │
│  └──────────────────────────────────────┘   │
└──────────────────┬──────────────────────────┘
                   │
┌──────────────────┴──────────────────────────┐
│           External AI APIs                  │
│  ┌──────────┬──────────┬────────────────┐   │
│  │ Claude   │ OpenAI   │   Google AI    │   │
│  │ Messages │   Chat   │    Gemini      │   │
│  │   API    │   API    │  Studio API    │   │
│  └──────────┴──────────┴────────────────┘   │
└─────────────────────────────────────────────┘
```

### 핵심 설계 원칙

1. **통합 인터페이스**: 사용자는 AI를 선택하기만 하면 됨
2. **스트리밍 우선**: 모든 AI의 응답을 실시간 스트리밍
3. **비용 투명성**: 토큰 사용량 및 예상 비용 실시간 표시
4. **확장 가능성**: 새로운 AI 추가 시 최소한의 코드 수정

---

## 🔍 AI별 특징 비교

### 종합 비교표

| 항목 | Claude (Anthropic) | GPT (OpenAI) | Gemini (Google) |
|------|-------------------|--------------|-----------------|
| **최신 모델** | Claude 4.5 Sonnet | GPT-4 Turbo | Gemini 2.0 Flash |
| **컨텍스트 윈도우** | 200K tokens | 128K tokens | 2M tokens 🏆 |
| **가격 (입력/출력)** | $3/$15 per 1M | $10/$30 per 1M | $0.075/$0.30 per 1M 🏆 |
| **무료 티어** | ❌ | ❌ | ✅ (AI Studio) |
| **스트리밍 지원** | ✅ SSE | ✅ SSE | ✅ SSE |
| **캐싱** | ✅ (5분, 90% 할인) | ❌ | ✅ |
| **파일 업로드** | ✅ (20MB) | ✅ | ✅ (2GB) 🏆 |
| **이미지 입력** | ✅ | ✅ | ✅ |
| **비디오 입력** | ❌ | ❌ | ✅ 🏆 |
| **JSON 모드** | ✅ | ✅ | ✅ |
| **함수 호출** | ✅ (Tools) | ✅ (Functions) | ✅ (Function Calling) |
| **안전 필터** | 중간 | 높음 | 커스터마이징 가능 🏆 |
| **코딩 능력** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **추론 능력** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **창의성** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **한국어 지원** | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ 🏆 |

### AI별 최적 사용 시나리오

#### Claude 4.5 Sonnet
**강점**:
- 장문 분석 및 요약 (200K 컨텍스트)
- 코드 생성 및 리팩토링
- 복잡한 추론 작업
- XML 구조화된 출력

**추천 용도**:
- 📝 기술 문서 작성
- 💻 코드 리뷰 및 최적화
- 📊 데이터 분석 리포트
- 🔍 법률/계약서 검토

#### GPT-4 Turbo
**강점**:
- 창의적 글쓰기
- 브레인스토밍
- 다양한 언어 번역
- 일반적인 대화

**추천 용도**:
- ✍️ 마케팅 카피 작성
- 🎨 아이디어 발상
- 🌐 다국어 콘텐츠 제작
- 💬 고객 상담 챗봇

#### Gemini 2.0 Flash
**강점**:
- 무료 또는 저렴한 비용
- 초대용량 컨텍스트 (2M tokens)
- 멀티모달 (이미지, 비디오)
- 빠른 응답 속도

**추천 용도**:
- 🎥 비디오 분석 및 요약
- 📷 이미지 설명 생성
- 📚 대량 문서 처리
- 🆓 무료 프로토타입 개발

---

## 📅 Phase별 구현 계획

### Phase 1: 기본 통합 (Week 1-2)

**목표**: 3개 AI와 기본 채팅 기능 구현

#### 백엔드 작업
- [x] FastAPI 프로젝트 구조 생성
- [ ] Claude API 통합
  - [ ] Messages API 연동
  - [ ] 스트리밍 응답 처리
  - [ ] 에러 핸들링
- [ ] GPT API 통합
  - [ ] Chat Completions API 연동
  - [ ] 스트리밍 응답 처리
  - [ ] 에러 핸들링
- [ ] Gemini API 통합
  - [ ] Generate Content API 연동
  - [ ] AI Studio 무료 키 지원
  - [ ] 스트리밍 응답 처리

#### 프론트엔드 작업
- [ ] 기본 채팅 UI 구현
- [ ] AI 선택 드롭다운
- [ ] 메시지 전송/수신 기능
- [ ] 스트리밍 응답 표시

#### 테스트
- [ ] 각 AI별 기본 응답 테스트
- [ ] 에러 시나리오 테스트
- [ ] API 키 검증 테스트

**예상 소요 시간**: 40시간

---

### Phase 2: 고급 기능 (Week 3-4)

**목표**: 토큰 추적, 프리셋, 히스토리

#### 백엔드 작업
- [ ] Token Counter 구현
  - [ ] AI별 토큰 계산 로직
  - [ ] 누적 토큰 추적
  - [ ] 비용 계산 엔진
- [ ] Preset System
  - [ ] 프리셋 CRUD API
  - [ ] 시스템 프롬프트 관리
  - [ ] 프리셋 불러오기
- [ ] History Manager
  - [ ] 대화 저장 (SQLite/JSON)
  - [ ] 대화 불러오기
  - [ ] 대화 검색 기능

#### 프론트엔드 작업
- [ ] 토큰 카운터 UI
  - [ ] 실시간 토큰 표시
  - [ ] 비용 예상 표시
  - [ ] 사용량 차트
- [ ] 프리셋 관리 UI
  - [ ] 프리셋 목록
  - [ ] 프리셋 편집기
  - [ ] 빠른 적용 버튼
- [ ] 히스토리 사이드바
  - [ ] 대화 목록
  - [ ] 검색 기능
  - [ ] 대화 불러오기

**예상 소요 시간**: 50시간

---

### Phase 3: 멀티모달 & 최적화 (Week 5-6)

**목표**: 파일 업로드, 캐싱, 성능 최적화

#### 백엔드 작업
- [ ] File Upload Handler
  - [ ] 이미지 업로드 (Claude, GPT, Gemini)
  - [ ] 문서 업로드 (PDF, TXT, DOCX)
  - [ ] 비디오 업로드 (Gemini만)
  - [ ] 파일 타입 검증
  - [ ] 파일 크기 제한
- [ ] Caching Layer
  - [ ] Claude Prompt Caching
  - [ ] Gemini Context Caching
  - [ ] Redis 캐시 (선택)
- [ ] Performance Optimization
  - [ ] 비동기 처리 최적화
  - [ ] 메모리 사용 최적화
  - [ ] Rate Limiting

#### 프론트엔드 작업
- [ ] 파일 업로드 UI
  - [ ] Drag & Drop
  - [ ] 파일 미리보기
  - [ ] 업로드 진행률
- [ ] 성능 개선
  - [ ] Virtual Scrolling (긴 대화)
  - [ ] 이미지 Lazy Loading
  - [ ] 코드 스플리팅

**예상 소요 시간**: 45시간

---

### Phase 4: 프로덕션 준비 (Week 7-8)

**목표**: 배포, 모니터링, 문서화

#### DevOps
- [ ] Docker 컨테이너화
- [ ] Docker Compose 설정
- [ ] 환경 변수 관리
- [ ] HTTPS 설정
- [ ] 도메인 연결

#### 모니터링
- [ ] 로깅 시스템
- [ ] 에러 추적 (Sentry)
- [ ] API 사용량 모니터링
- [ ] 성능 메트릭

#### 문서화
- [ ] API 문서 (OpenAPI/Swagger)
- [ ] 사용자 가이드
- [ ] 개발자 문서
- [ ] 배포 가이드

**예상 소요 시간**: 30시간

---

## 🛠️ 기술 스택 결정

### 백엔드

```python
# 핵심 프레임워크
fastapi = "0.104.1"          # 고성능 비동기 웹 프레임워크
uvicorn = "0.24.0"           # ASGI 서버
pydantic = "2.5.0"           # 데이터 검증

# AI SDK
anthropic = "0.7.7"          # Claude API
openai = "1.3.7"             # GPT API  
google-generativeai = "0.3.1" # Gemini API

# 유틸리티
python-dotenv = "1.0.0"      # 환경 변수
tiktoken = "0.5.1"           # GPT 토큰 계산
httpx = "0.25.1"             # 비동기 HTTP
aiofiles = "23.2.1"          # 비동기 파일 처리

# 데이터베이스 (선택)
sqlalchemy = "2.0.23"        # ORM
aiosqlite = "0.19.0"         # 비동기 SQLite

# 캐싱 (선택)
redis = "5.0.1"              # Redis 캐시
aioredis = "2.0.1"           # 비동기 Redis
```

### 프론트엔드

**옵션 1: Vanilla JS + Tailwind (빠른 프로토타입)**
```html
<!-- 장점: 빌드 없음, 간단함 -->
<!-- 단점: 복잡한 상태 관리 어려움 -->
```

**옵션 2: React + Vite (권장)**
```json
{
  "react": "^18.2.0",
  "vite": "^5.0.0",
  "tailwindcss": "^3.3.0",
  "axios": "^1.6.0",
  "zustand": "^4.4.0",           // 상태 관리 (가벼움)
  "react-markdown": "^9.0.0",     // 마크다운 렌더링
  "react-syntax-highlighter": "^15.5.0" // 코드 하이라이팅
}
```

### 배포

```yaml
# Docker
- Docker: 20.10+
- Docker Compose: 2.0+

# 클라우드 (선택)
- Vercel (프론트엔드)
- Railway (백엔드)
- Fly.io (백엔드)
- AWS EC2 (전체)
```

---

## 🔌 API 통합 전략

### 통합 라우터 설계

```python
# app/routers/chat.py

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from typing import Literal

router = APIRouter(prefix="/api/chat", tags=["chat"])

@router.post("/stream")
async def chat_stream(
    ai_provider: Literal["claude", "gpt", "gemini"],
    message: str,
    api_key: str,
    model: str = None,
    temperature: float = 1.0,
    max_tokens: int = 4096
):
    """
    통합 채팅 엔드포인트
    - ai_provider: AI 선택 (claude/gpt/gemini)
    - message: 사용자 메시지
    - api_key: API 키
    - model: 모델 선택 (없으면 기본값)
    - temperature: 창의성 (0-2)
    - max_tokens: 최대 토큰
    """
    
    # AI별 핸들러 라우팅
    if ai_provider == "claude":
        handler = ClaudeHandler(api_key)
    elif ai_provider == "gpt":
        handler = GPTHandler(api_key)
    elif ai_provider == "gemini":
        handler = GeminiHandler(api_key)
    else:
        raise HTTPException(400, "Invalid AI provider")
    
    # 스트리밍 응답 생성
    return StreamingResponse(
        handler.stream_chat(
            message=message,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        ),
        media_type="text/event-stream"
    )
```

### AI별 핸들러 구현

#### Claude Handler

```python
# app/handlers/claude_handler.py

from anthropic import AsyncAnthropic
import json

class ClaudeHandler:
    def __init__(self, api_key: str):
        self.client = AsyncAnthropic(api_key=api_key)
        self.default_model = "claude-sonnet-4-20250514"
    
    async def stream_chat(
        self, 
        message: str,
        model: str = None,
        temperature: float = 1.0,
        max_tokens: int = 4096
    ):
        """Claude 스트리밍 응답"""
        
        model = model or self.default_model
        
        try:
            async with self.client.messages.stream(
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                messages=[{"role": "user", "content": message}]
            ) as stream:
                
                # 스트림 시작 메타데이터
                yield f"data: {json.dumps({'type': 'start', 'ai': 'claude', 'model': model})}\n\n"
                
                # 텍스트 청크
                async for text in stream.text_stream:
                    yield f"data: {json.dumps({'type': 'text', 'content': text})}\n\n"
                
                # 스트림 종료 메타데이터
                final_message = await stream.get_final_message()
                yield f"data: {json.dumps({
                    'type': 'end',
                    'usage': {
                        'input_tokens': final_message.usage.input_tokens,
                        'output_tokens': final_message.usage.output_tokens,
                        'cache_read_input_tokens': final_message.usage.cache_read_input_tokens,
                        'cache_creation_input_tokens': final_message.usage.cache_creation_input_tokens
                    },
                    'stop_reason': final_message.stop_reason
                })}\n\n"
                
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
```

#### GPT Handler

```python
# app/handlers/gpt_handler.py

from openai import AsyncOpenAI
import json

class GPTHandler:
    def __init__(self, api_key: str):
        self.client = AsyncOpenAI(api_key=api_key)
        self.default_model = "gpt-4-turbo-preview"
    
    async def stream_chat(
        self,
        message: str,
        model: str = None,
        temperature: float = 1.0,
        max_tokens: int = 4096
    ):
        """GPT 스트리밍 응답"""
        
        model = model or self.default_model
        
        try:
            stream = await self.client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": message}],
                temperature=temperature,
                max_tokens=max_tokens,
                stream=True
            )
            
            # 스트림 시작
            yield f"data: {json.dumps({'type': 'start', 'ai': 'gpt', 'model': model})}\n\n"
            
            total_tokens = 0
            
            async for chunk in stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    yield f"data: {json.dumps({'type': 'text', 'content': content})}\n\n"
                
                # 마지막 청크에서 사용량 정보
                if chunk.choices[0].finish_reason:
                    yield f"data: {json.dumps({
                        'type': 'end',
                        'usage': {
                            'prompt_tokens': chunk.usage.prompt_tokens if chunk.usage else 0,
                            'completion_tokens': chunk.usage.completion_tokens if chunk.usage else 0,
                            'total_tokens': chunk.usage.total_tokens if chunk.usage else 0
                        },
                        'finish_reason': chunk.choices[0].finish_reason
                    })}\n\n"
        
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
```

#### Gemini Handler

```python
# app/handlers/gemini_handler.py

import google.generativeai as genai
import json

class GeminiHandler:
    def __init__(self, api_key: str):
        genai.configure(api_key=api_key)
        self.default_model = "gemini-2.0-flash-exp"
    
    async def stream_chat(
        self,
        message: str,
        model: str = None,
        temperature: float = 1.0,
        max_tokens: int = 8192
    ):
        """Gemini 스트리밍 응답"""
        
        model_name = model or self.default_model
        
        try:
            model = genai.GenerativeModel(model_name)
            
            # 스트림 시작
            yield f"data: {json.dumps({'type': 'start', 'ai': 'gemini', 'model': model_name})}\n\n"
            
            # 스트리밍 생성
            response = model.generate_content(
                message,
                generation_config=genai.types.GenerationConfig(
                    temperature=temperature,
                    max_output_tokens=max_tokens
                ),
                stream=True
            )
            
            total_tokens = 0
            
            for chunk in response:
                if chunk.text:
                    yield f"data: {json.dumps({'type': 'text', 'content': chunk.text})}\n\n"
            
            # 종료 (Gemini는 토큰 정보 제공 안 함)
            yield f"data: {json.dumps({
                'type': 'end',
                'usage': {'note': 'Gemini does not provide token counts in real-time'},
                'finish_reason': 'stop'
            })}\n\n"
        
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
```

---

## 💰 비용 최적화 전략

### 1. Prompt Caching (Claude)

Claude는 5분 동안 프롬프트를 캐싱하여 비용을 90% 절감:

```python
# 캐싱 활용 예시
messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text": "긴 시스템 프롬프트...",
                "cache_control": {"type": "ephemeral"}  # 캐싱 활성화
            },
            {
                "type": "text",
                "text": "실제 사용자 질문"
            }
        ]
    }
]
```

**절감 효과**:
- 일반 입력 토큰: $3 / 1M tokens
- 캐시된 토큰: $0.30 / 1M tokens (90% 할인)

### 2. Context Caching (Gemini)

Gemini는 긴 컨텍스트를 캐싱하여 비용 절감:

```python
# Gemini 캐싱 예시
model = genai.GenerativeModel(
    "gemini-2.0-flash-exp",
    system_instruction="긴 시스템 프롬프트..."  # 자동 캐싱
)
```

### 3. 토큰 제한 설정

불필요한 토큰 사용 방지:

```python
# AI별 최적 토큰 제한
TOKEN_LIMITS = {
    "claude": {
        "default": 4096,
        "short": 1024,
        "long": 8192
    },
    "gpt": {
        "default": 4096,
        "short": 1024,
        "long": 16384
    },
    "gemini": {
        "default": 8192,
        "short": 2048,
        "long": 32768
    }
}
```

### 4. 무료 티어 우선 사용

Gemini AI Studio는 무료:
- 2M 컨텍스트
- 분당 15 요청
- 일일 1,500 요청

**전략**: 프로토타입이나 가벼운 작업은 Gemini 우선 사용

---

## 🎨 UI/UX 설계

### 메인 채팅 인터페이스

```
┌──────────────────────────────────────────────────────────────┐
│ 🤖 Multi-AI Chat                          [Settings] [Theme] │
├──────────────────────────────────────────────────────────────┤
│                                                                │
│ ┌────────────────────────────────────────────────────────┐   │
│ │ Select AI:  [ Claude 4.5 Sonnet ▼ ]                   │   │
│ │                                                          │   │
│ │ Presets:    [ Creative Writing ▼ ]                     │   │
│ └────────────────────────────────────────────────────────┘   │
│                                                                │
│ ┌────────────────────────────────────────────────────────┐   │
│ │                    Chat Messages                        │   │
│ │ ┌────────────────────────────────────────────────────┐ │   │
│ │ │ 👤 User                                             │ │   │
│ │ │ 안녕하세요, Python 코드를 작성해줄 수 있나요?        │ │   │
│ │ └────────────────────────────────────────────────────┘ │   │
│ │                                                          │   │
│ │ ┌────────────────────────────────────────────────────┐ │   │
│ │ │ 🤖 Claude 4.5 Sonnet                     [Copy]    │ │   │
│ │ │ 물론입니다! 어떤 코드를 작성해드릴까요?            │ │   │
│ │ │                                                      │ │   │
│ │ │ ```python                                            │ │   │
│ │ │ def hello():                                         │ │   │
│ │ │     print("Hello, World!")                           │ │   │
│ │ │ ```                                                  │ │   │
│ │ │                                                      │ │   │
│ │ │ 📊 Tokens: 150 in | 80 out | Cost: $0.0012         │ │   │
│ │ └────────────────────────────────────────────────────┘ │   │
│ │                                                          │   │
│ │ [Streaming...▌]                                         │   │
│ └────────────────────────────────────────────────────────┘   │
│                                                                │
│ ┌────────────────────────────────────────────────────────┐   │
│ │ Type a message...                        [📎] [Send]   │   │
│ └────────────────────────────────────────────────────────┘   │
│                                                                │
│ ┌────────────────────────────────────────────────────────┐   │
│ │ 💰 Total Cost Today: $0.15                             │   │
│ │ 🎫 Tokens Used: 12,450 / 200,000                       │   │
│ └────────────────────────────────────────────────────────┘   │
└──────────────────────────────────────────────────────────────┘
```

### 설정 패널

```
┌─────────────────────────────────────────────┐
│            Settings                          │
├─────────────────────────────────────────────┤
│                                               │
│ 🔑 API Keys                                  │
│ ┌───────────────────────────────────────┐   │
│ │ Claude API Key:  [sk-ant-api...] [✓] │   │
│ │ OpenAI API Key:  [sk-...] [✓]        │   │
│ │ Gemini API Key:  [AIza...] [✓]       │   │
│ └───────────────────────────────────────┘   │
│                                               │
│ 🎨 Theme                                     │
│ ┌───────────────────────────────────────┐   │
│ │ ( ) Light  (•) Dark  ( ) Auto         │   │
│ └───────────────────────────────────────┘   │
│                                               │
│ 🧠 Default Settings                          │
│ ┌───────────────────────────────────────┐   │
│ │ Temperature:  [========|    ] 1.0      │   │
│ │ Max Tokens:   [4096        ▼]         │   │
│ └───────────────────────────────────────┘   │
│                                               │
│ 💾 Data                                      │
│ ┌───────────────────────────────────────┐   │
│ │ [Export Conversations]                 │   │
│ │ [Clear All History]                    │   │
│ │ [Delete All Data]                      │   │
│ └───────────────────────────────────────┘   │
│                                               │
│               [Save] [Cancel]                │
└─────────────────────────────────────────────┘
```

---

## ✅ 구현 우선순위

### Must Have (P0) - 2주 내 완료

1. **기본 채팅 기능**
   - [ ] Claude API 통합 및 스트리밍
   - [ ] GPT API 통합 및 스트리밍
   - [ ] Gemini API 통합 및 스트리밍
   - [ ] AI 선택 UI
   - [ ] 메시지 전송/수신

2. **에러 처리**
   - [ ] API 키 검증
   - [ ] 네트워크 에러 핸들링
   - [ ] Rate Limit 처리
   - [ ] 사용자 친화적 에러 메시지

3. **기본 UI**
   - [ ] 깔끔한 채팅 인터페이스
   - [ ] 다크/라이트 테마
   - [ ] 반응형 디자인

---

### Should Have (P1) - 4주 내 완료

4. **토큰 추적**
   - [ ] 실시간 토큰 카운터
   - [ ] 비용 계산 및 표시
   - [ ] 일일/월별 사용량 통계

5. **프리셋 시스템**
   - [ ] 프리셋 생성/수정/삭제
   - [ ] 시스템 프롬프트 관리
   - [ ] 빠른 적용 기능

6. **대화 히스토리**
   - [ ] 대화 저장 (로컬/서버)
   - [ ] 대화 목록 및 검색
   - [ ] 대화 불러오기

---

### Nice to Have (P2) - 6주 내 완료

7. **멀티모달**
   - [ ] 이미지 업로드 및 분석
   - [ ] 문서 업로드 (PDF, DOCX)
   - [ ] 비디오 업로드 (Gemini)

8. **고급 기능**
   - [ ] 대화 포크 (분기)
   - [ ] 응답 재생성
   - [ ] 모델 간 비교 모드
   - [ ] 사이드바 메모

9. **최적화**
   - [ ] Prompt Caching 구현
   - [ ] Redis 캐싱
   - [ ] 성능 모니터링

---

## 📦 프로젝트 구조

```
multi-ai-chat/
├── backend/                    # FastAPI 백엔드
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py            # FastAPI 앱 진입점
│   │   ├── config.py          # 설정 및 환경 변수
│   │   ├── models.py          # Pydantic 모델
│   │   ├── routers/
│   │   │   ├── __init__.py
│   │   │   ├── chat.py        # 채팅 엔드포인트
│   │   │   ├── presets.py     # 프리셋 관리
│   │   │   └── history.py     # 히스토리 관리
│   │   ├── handlers/
│   │   │   ├── __init__.py
│   │   │   ├── claude_handler.py
│   │   │   ├── gpt_handler.py
│   │   │   └── gemini_handler.py
│   │   ├── services/
│   │   │   ├── __init__.py
│   │   │   ├── token_counter.py
│   │   │   ├── cost_calculator.py
│   │   │   └── cache_manager.py
│   │   └── utils/
│   │       ├── __init__.py
│   │       ├── error_handler.py
│   │       └── validators.py
│   ├── requirements.txt
│   ├── Dockerfile
│   └── .env.example
│
├── frontend/                   # React 프론트엔드
│   ├── public/
│   ├── src/
│   │   ├── components/
│   │   │   ├── ChatInterface.jsx
│   │   │   ├── MessageBubble.jsx
│   │   │   ├── AISelector.jsx
│   │   │   ├── TokenCounter.jsx
│   │   │   ├── PresetManager.jsx
│   │   │   └── SettingsPanel.jsx
│   │   ├── hooks/
│   │   │   ├── useChat.js
│   │   │   ├── useStreamingResponse.js
│   │   │   └── useTokenCounter.js
│   │   ├── services/
│   │   │   ├── api.js
│   │   │   └── eventSource.js
│   │   ├── store/
│   │   │   ├── chatStore.js
│   │   │   ├── settingsStore.js
│   │   │   └── historyStore.js
│   │   ├── utils/
│   │   │   ├── formatters.js
│   │   │   └── validators.js
│   │   ├── App.jsx
│   │   └── main.jsx
│   ├── package.json
│   ├── vite.config.js
│   └── tailwind.config.js
│
├── docker-compose.yml
├── README.md
└── docs/
    ├── API.md
    ├── DEPLOYMENT.md
    └── USER_GUIDE.md
```

---

## 🚀 다음 단계

1. **GPT와 Gemini 제안서 전체 검토**
   - 두 문서를 업로드하면 상세 분석 시작
   - 각 제안의 장단점 비교
   - 최적 통합 방안 결정

2. **백엔드 코드 생성**
   - FastAPI 프로젝트 구조 생성
   - AI별 핸들러 구현
   - API 엔드포인트 구현

3. **프론트엔드 코드 생성**
   - React 앱 구조 생성
   - 채팅 인터페이스 구현
   - SSE 스트리밍 구현

4. **Docker 설정**
   - Dockerfile 작성
   - docker-compose.yml 작성
   - 환경 변수 템플릿

---

**이제 GPT와 Gemini 제안서를 업로드해주시면, 구체적인 통합 작업을 시작하겠습니다!** 🚀
