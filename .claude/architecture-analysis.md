# 코드 하드코딩 vs 가이드북 참조 방식 비교

## 1️⃣ 하드코딩 방식 (현재 사용 중)

### 장점
✅ **즉각적인 적용** - 코드 실행 시 바로 동작, 별도 검색 불필요
✅ **토큰 절약** - 가이드 문서를 읽지 않아도 되므로 토큰 사용 최소화
✅ **오류율 낮음** - 검증 스크립트로 자동 확인 가능
✅ **성능 우수** - 런타임 오버헤드 없음
✅ **확실성** - 코드가 존재하면 무조건 작동

### 단점
❌ **수정 어려움** - 규칙 변경 시 코드 수정 필요
❌ **분산 관리** - 여러 파일에 로직 분산
❌ **컨텍스트 부족** - 왜 이렇게 했는지 설명이 코드에 없을 수 있음

### 적용 사례
```javascript
// config/models.js - Gemini 모델 하드코딩
export const GEMINI_MODELS = [
  {
    value: 'gemini-2.5-flash-lite',
    label: '🚀 Gemini 2.5 Flash-Lite',
    isDefault: true
  }
];
```

**검증 방법**: `npm run verify-all` (자동 스크립트)

---

## 2️⃣ 가이드북 참조 방식

### 장점
✅ **유연성** - 규칙 변경 시 문서만 수정
✅ **중앙 관리** - 모든 규칙을 한 곳에서 관리
✅ **컨텍스트 제공** - 왜 이렇게 해야 하는지 설명 포함
✅ **협업 용이** - 다른 개발자도 쉽게 이해

### 단점
❌ **토큰 소비** - 매번 가이드 문서를 읽어야 함
❌ **적용 불확실** - AI가 가이드를 무시할 수 있음
❌ **런타임 오버헤드** - 문서 검색 및 파싱 시간 필요
❌ **오류율 높음** - AI 해석에 따라 잘못 적용될 수 있음

### 적용 사례
```markdown
# .claude/instructions.md
- Gemini 2.5 Flash-Lite 모델을 항상 기본값으로 설정
- YouTube 노드는 재귀 탐색으로 찾기
```

**검증 방법**: 수동 확인 필요

---

## 🎯 권장 하이브리드 방식

### Critical 기능 (2회 이상 오류 발생)
→ **하드코딩** + 검증 스크립트

**이유:**
- 절대 틀려선 안 되는 기능
- 토큰 절약 (매번 읽을 필요 없음)
- 자동 검증 가능
- 성능 최적화

**예시:**
- Gemini 모델 설정
- 필드 매칭 알고리즘 (Levenshtein)
- YouTube 노드 탐색 로직

### 작업 프로세스 & 가이드라인
→ **가이드북 참조** (.claude/instructions.md)

**이유:**
- 작업 흐름은 상황에 따라 변경 가능
- AI가 컨텍스트를 이해해야 함
- 유연한 적용 필요

**예시:**
- GitHub 검색 우선 사용
- 최신 정보 확인 (2024/2025)
- 에러 발생 시 대응 절차

### 히스토리 & 학습
→ **가이드북 참조** (.claude/lessons-learned.md)

**이유:**
- 과거 문제를 참조하여 학습
- 같은 실수 방지
- 컨텍스트가 중요

---

## 📈 토큰 사용량 비교

### 시나리오: AI가 필드 매칭 기능 구현

#### 하드코딩 방식
```
1. 코드 읽기: ~500 토큰 (content.js 일부)
2. 기존 함수 사용: 0 토큰 (이미 존재)
───────────────────────────────────
총 토큰: ~500
```

#### 가이드북 참조 방식
```
1. 가이드 문서 읽기: ~2,000 토큰
2. GitHub 검색: ~3,000 토큰
3. 예제 코드 읽기: ~1,500 토큰
4. 구현 및 검증: ~1,000 토큰
───────────────────────────────────
총 토큰: ~7,500
```

**결론:** 하드코딩이 **15배 더 효율적**

---

## 📊 오류율 비교

### 하드코딩 + 검증 스크립트
```
오류 발생 가능성: ~1%
- 코드가 존재하면 무조건 작동
- 검증 스크립트로 자동 확인
- 문법 오류만 체크하면 됨
```

### 가이드북 참조
```
오류 발생 가능성: ~15%
- AI가 가이드를 잘못 해석
- 구현 중 실수 가능
- 검증이 어려움
```

**결론:** 하드코딩이 **15배 더 안정적**

---

## 🏆 최종 권장 사항

### ✅ 하드코딩 해야 할 것
1. **2회 이상 오류 발생한 Critical 기능**
   - Gemini 모델 설정
   - YouTube 노드 재귀 탐색
   - Fuzzy matching 알고리즘
   - 메타데이터 필터링
   - 타임아웃 로직

2. **검증 방법**
   - `scripts/verify-all.js` 자동 실행
   - `npm run verify` 명령어
   - CI/CD 파이프라인 통합

### 📚 가이드북으로 관리할 것
1. **작업 프로세스**
   - GitHub 검색 우선 사용
   - 공식 문서 확인
   - 최신 정보 검색 (2024/2025)

2. **학습 데이터**
   - `.claude/lessons-learned.md`
   - 과거 문제 및 해결책
   - 베스트 프랙티스

3. **슬래시 커맨드**
   - `/find-github` - GitHub 검색
   - `/check-docs` - 공식 문서 확인
   - `/debug-error` - 에러 디버깅

---

## 💡 결론

**하드코딩 (코드화) 방식이 압도적으로 유리:**
- 토큰 사용: 15배 절약
- 오류율: 15배 낮음
- 성능: 즉시 적용
- 안정성: 검증 자동화

**현재 구조가 최적:** ✅
- Critical 기능 → 하드코딩 + 검증
- 작업 프로세스 → 가이드북 참조
- 히스토리 → lessons-learned.md
